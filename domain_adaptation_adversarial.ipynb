{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mounting Google Drive from Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the current working directory to the Google Drive\n",
    "#%cd /content/drive/My Drive/MLDL2024_project1-Enrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.gta5 import GTA5Custom\n",
    "from datasets.cityscapes import CityscapesCustom\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from models.discriminator.discriminator import FCDiscriminator\n",
    "#from train_adversarial import train_adversarial\n",
    "from utils import test_latency_FPS, test_FLOPs_params, plot_miou_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Set device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "#Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "#Set training parameters\n",
    "gta5_height, gta5_width = (8, 16)\n",
    "gta5_batch_size = 8\n",
    "\n",
    "cityscapes_height, cityscapes_width = (8, 16)\n",
    "cityscapes_batch_size = 8\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "lambda_adv = 0.001\n",
    "\n",
    "#Set up the interpolation layers\n",
    "interp_s = nn.Upsample(size=(gta5_height, gta5_width), mode='bilinear')\n",
    "interp_t = nn.Upsample(size=(cityscapes_height, cityscapes_width), mode='bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTA5 (Train): 2500 images, divided into 313 batches of size 8\n",
      "Cityscapes (Test): 500 images, divided into 63 batches of size 8\n"
     ]
    }
   ],
   "source": [
    "#Create Dataloaders for Cityscapes and GTA5\n",
    "gta5_dir = os.path.dirname(os.getcwd()) + '/GTA5/GTA5/'\n",
    "cityscapes_dir = os.path.dirname(os.getcwd()) + '/Cityscapes/Cityspaces/'\n",
    "\n",
    "augment1 = transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3)\n",
    "gta5_train_dataset_aug1 = GTA5Custom(gta5_dir, gta5_height, gta5_width, augment=augment1)\n",
    "cityscapes_test_dataset = CityscapesCustom(cityscapes_dir, 'val', cityscapes_height, cityscapes_width)\n",
    "\n",
    "gta5_train_dataloader_aug1 = DataLoader(gta5_train_dataset_aug1, gta5_batch_size, shuffle=True)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, cityscapes_batch_size, shuffle=False)\n",
    "\n",
    "#Get the class names\n",
    "class_names = cityscapes_test_dataset.get_class_names()\n",
    "\n",
    "print(f'GTA5 (Train): {len(gta5_train_dataset_aug1)} images, divided into {len(gta5_train_dataloader_aug1)} batches of size {gta5_train_dataloader_aug1.batch_size}')\n",
    "print(f'Cityscapes (Test): {len(cityscapes_test_dataset)} images, divided into {len(cityscapes_test_dataloader)} batches of size {cityscapes_test_dataloader.batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the segmentation network (our Generator) with the pretrained weights\n",
    "g_model = BiSeNet(num_classes=19, context_path='resnet18').to(device)\n",
    "\n",
    "#Set up the loss function and the optimizer for the Generator\n",
    "g_criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "g_optimizer = torch.optim.SGD(g_model.parameters(), lr=2.5e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the Discriminator\n",
    "d_model = FCDiscriminator(num_classes=19).to(device)\n",
    "\n",
    "#Set up the loss function and the optimizer for the Discriminator\n",
    "d_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "d_optimizer = torch.optim.Adam(d_model.parameters(), lr=1e-4, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation loops\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "\n",
    "def train_adversarial(g_model, d_model, g_criterion, d_criterion, g_optimizer, d_optimizer, lambda_adv, s_dataloader, t_dataloader, interp_s, interp_t, class_names, device, n_epochs, model_name):\n",
    "    n_classes = len(class_names)\n",
    "    #g_initial_lr = g_optimizer.param_groups[0]['lr']\n",
    "    #d_initial_lr = d_optimizer.param_groups[0]['lr']\n",
    "    best_miou = 0.0\n",
    "    best_class_iou = np.zeros(n_classes)\n",
    "    best_epoch = 0\n",
    "    all_train_miou = []\n",
    "    all_test_miou = []\n",
    "\n",
    "    #Labels for adversarial training\n",
    "    source_label = torch.ones((s_dataloader.batch_size, 1, 1, 1)).to(device)#0\n",
    "    target_label = torch.zeros((t_dataloader.batch_size, 1, 1, 1)).to(device)#1\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        g_model.train()\n",
    "        d_model.train()\n",
    "        train_hist = np.zeros((n_classes, n_classes))\n",
    "        train_loop = tqdm(zip(s_dataloader, t_dataloader), total=len(s_dataloader)+len(t_dataloader), leave=False)\n",
    "        for (source_data, source_labels), (target_data, _) in train_loop:\n",
    "            source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
    "            target_data = target_data.to(device)\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "\n",
    "            #TRAIN G\n",
    "\n",
    "            #Do not accumulate gradients for the Discriminator\n",
    "            for param in d_model.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            #Train with source\n",
    "            g_source_output, _, _ = g_model(source_data)\n",
    "            print(f'gsource: {g_source_output.shape}, {g_source_output.dtype}')\n",
    "            #g_source_output = interp_s(g_source_output)\n",
    "\n",
    "            g_loss_seg = g_criterion(g_source_output, source_labels)\n",
    "            g_loss_seg.backward()\n",
    "\n",
    "            #Train with target\n",
    "            g_target_output, _, _ = g_model(target_data)\n",
    "            print(f'gtarget: {g_target_output.shape}, {g_target_output.dtype}')\n",
    "            #g_target_output = interp_t(g_target_output)\n",
    "\n",
    "            d_out = d_model(F.softmax(g_target_output))\n",
    "            print(f'dout: {d_out.shape}, {d_out.dtype}')\n",
    "\n",
    "            loss_adv_t = d_criterion(d_out, source_label)\n",
    "            loss_d = lambda_adv * loss_adv_t\n",
    "            loss_d.backward()\n",
    "\n",
    "            #TRAIN D\n",
    "\n",
    "            ###CONTINUE HERE###\n",
    "\n",
    "\n",
    "            #Compute the adversarial loss\n",
    "            d_source_output = d_model(F.softmax(g_source_output))\n",
    "            print(f'dsource: {d_source_output.shape}, {d_source_output.dtype}')\n",
    "            d_target_output = d_model(F.softmax(g_target_output))\n",
    "            print(f'dtarget: {d_target_output.shape}, {d_target_output.dtype}')\n",
    "            \n",
    "            d_loss = d_criterion(d_source_output, torch.ones_like(d_source_output)) + d_criterion(d_target_output, torch.zeros_like(d_target_output))\n",
    "            g_loss = g_loss_seg + lambda_adv * d_loss\n",
    "\n",
    "            #Backward pass\n",
    "            g_loss.backward()\n",
    "            #poly_lr_scheduler(g_optimizer, init_lr=g_initial_lr, iter=epoch, max_iter=n_epochs)\n",
    "            g_optimizer.step()\n",
    "\n",
    "            d_loss.backward()\n",
    "            #poly_lr_scheduler(d_optimizer, init_lr=d_initial_lr, iter=epoch, max_iter=n_epochs)\n",
    "            d_optimizer.step()\n",
    "\n",
    "            predictions = torch.argmax(g_source_output, dim=1)\n",
    "\n",
    "            train_hist += fast_hist(source_labels.cpu().numpy(), predictions.cpu().numpy(), n_classes)\n",
    "            train_loop.set_description(f'Epoch {epoch+1}/{n_epochs} (Train)')\n",
    "\n",
    "        train_class_iou = 100*per_class_iou(train_hist)\n",
    "        train_miou = np.mean(train_class_iou)\n",
    "        all_train_miou.append(train_miou)\n",
    "\n",
    "        g_model.eval()\n",
    "        test_hist = np.zeros((n_classes, n_classes))\n",
    "        test_loop = tqdm(enumerate(t_dataloader), total=len(t_dataloader), leave=False)\n",
    "        with torch.no_grad():\n",
    "            for i, (target_data, target_labels) in test_loop:\n",
    "                target_data, target_labels = target_data.to(device), target_labels.to(device)\n",
    "\n",
    "                g_target_output = g_model(target_data)\n",
    "\n",
    "                predictions = torch.argmax(g_target_output, dim=1)\n",
    "                test_hist += fast_hist(target_labels.cpu().numpy(), predictions.cpu().numpy(), n_classes)\n",
    "                test_loop.set_description(f'Epoch {epoch+1}/{n_epochs} (Test)')\n",
    "\n",
    "        test_class_iou = 100*per_class_iou(test_hist)\n",
    "        test_miou = np.mean(test_class_iou)\n",
    "        all_test_miou.append(test_miou)\n",
    "\n",
    "        #Create a checkpoint dictionary\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': g_model.state_dict(),\n",
    "            'optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            'train_class_iou': train_class_iou,\n",
    "            'train_miou': train_miou,\n",
    "            'test_class_iou': test_class_iou,\n",
    "            'test_miou': test_miou,\n",
    "        }\n",
    "\n",
    "        #torch.save(checkpoint, f'checkpoints/{model_name}_checkpoint_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        #Early stopping condition\n",
    "        if test_miou > best_miou:\n",
    "            best_miou = test_miou\n",
    "            best_class_iou = test_class_iou\n",
    "            best_epoch = epoch\n",
    "            #torch.save(checkpoint, f'checkpoints/{model_name}_best_epoch_{epoch+1}.pth')\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(f'\\nEpoch {epoch+1}/{n_epochs} [{(end-start) // 60:.0f}m {(end-start) % 60:.0f}s]: Train mIoU={train_miou:.2f}%, Test mIoU={test_miou:.2f}%')\n",
    "        for class_name, iou in zip(class_names, test_class_iou):\n",
    "            print(f'{class_name}: {iou:.2f}%', end=' ')\n",
    "\n",
    "    print(f'\\nBest mIoU={best_miou:.2f}% at epoch {best_epoch+1}')\n",
    "    for class_name, iou in zip(class_names, best_class_iou):\n",
    "        print(f'{class_name}: {iou:.2f}%', end=' ')\n",
    "\n",
    "    return all_train_miou, all_test_miou, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/376 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsource: torch.Size([8, 19, 8, 16]), torch.float32\n",
      "gtarget: torch.Size([8, 19, 8, 16]), torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (3 x 4). Kernel size: (4 x 4). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m all_train_miou, all_test_miou, best_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_adversarial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_criterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_criterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mg_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_adv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mgta5_train_dataloader_aug1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcityscapes_test_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43minterp_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterp_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                              \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBiSeNet_adversarial\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m plot_miou_over_epochs(all_train_miou, all_test_miou, best_epoch, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBiSeNet_adversarial\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 60\u001b[0m, in \u001b[0;36mtrain_adversarial\u001b[1;34m(g_model, d_model, g_criterion, d_criterion, g_optimizer, d_optimizer, lambda_adv, s_dataloader, t_dataloader, interp_s, interp_t, class_names, device, n_epochs, model_name)\u001b[0m\n\u001b[0;32m     55\u001b[0m g_loss_seg \u001b[38;5;241m=\u001b[39m g_criterion(g_source_output, source_labels)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#Compute the adversarial loss\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#d_source_output = d_model(F.softmax(g_source_output))\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m#print(f'dsource: {d_source_output.shape}, {d_source_output.dtype}')\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m d_target_output \u001b[38;5;241m=\u001b[39m \u001b[43md_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_target_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtarget: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_target_output\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_target_output\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     63\u001b[0m d_loss \u001b[38;5;241m=\u001b[39m d_criterion(d_target_output, torch\u001b[38;5;241m.\u001b[39mzeros_like(d_target_output))\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enric\\Desktop\\MLDL2024_project1\\models\\discriminator\\discriminator.py:28\u001b[0m, in \u001b[0;36mFCDiscriminator.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n\u001b[0;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[1;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleaky_relu(x)\n\u001b[0;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(x)\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\enric\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (3 x 4). Kernel size: (4 x 4). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "all_train_miou, all_test_miou, best_epoch = train_adversarial(g_model, d_model, g_criterion, d_criterion,\n",
    "                                                              g_optimizer, d_optimizer, lambda_adv,\n",
    "                                                              gta5_train_dataloader_aug1, cityscapes_test_dataloader,\n",
    "                                                              interp_s, interp_t,\n",
    "                                                              class_names, device, n_epochs, 'BiSeNet_adversarial')\n",
    "\n",
    "plot_miou_over_epochs(all_train_miou, all_test_miou, best_epoch, 'BiSeNet_adversarial')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
