{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mounting Google Drive from Google Colab\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the current working directory to the Google Drive\n",
    "#%cd /content/drive/My Drive/MLDL2024_project1-Enrico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.gta5 import GTA5Custom\n",
    "from datasets.cityscapes import CityscapesCustom\n",
    "from models.bisenet.build_bisenet import BiSeNet\n",
    "from models.discriminator import FCDiscriminator\n",
    "from train_adversarial import train_adversarial\n",
    "from utils import test_latency_FPS, test_FLOPs_params, plot_miou_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "#Set device agnostic code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "#Set the manual seeds\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "#Set training parameters\n",
    "gta5_height, gta5_width = (8, 16)\n",
    "gta5_batch_size = 4\n",
    "\n",
    "cityscapes_height, cityscapes_width = (8, 16)\n",
    "cityscapes_batch_size = 4\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "lambda_adv = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GTA5 (Train): 2500 images, divided into 625 batches of size 4\n",
      "Cityscapes (Test): 500 images, divided into 125 batches of size 4\n"
     ]
    }
   ],
   "source": [
    "#Create Dataloaders for Cityscapes and GTA5\n",
    "gta5_dir = os.path.dirname(os.getcwd()) + '/GTA5/GTA5/'\n",
    "cityscapes_dir = os.path.dirname(os.getcwd()) + '/Cityscapes/Cityspaces/'\n",
    "\n",
    "augment1 = transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3)\n",
    "gta5_train_dataset_aug1 = GTA5Custom(gta5_dir, gta5_height, gta5_width, augment=augment1)\n",
    "cityscapes_test_dataset = CityscapesCustom(cityscapes_dir, 'val', cityscapes_height, cityscapes_width)\n",
    "\n",
    "gta5_train_dataloader_aug1 = DataLoader(gta5_train_dataset_aug1, gta5_batch_size, shuffle=True)\n",
    "cityscapes_test_dataloader = DataLoader(cityscapes_test_dataset, cityscapes_batch_size, shuffle=False)\n",
    "\n",
    "#Get the class names\n",
    "class_names = cityscapes_test_dataset.get_class_names()\n",
    "\n",
    "print(f'GTA5 (Train): {len(gta5_train_dataset_aug1)} images, divided into {len(gta5_train_dataloader_aug1)} batches of size {gta5_train_dataloader_aug1.batch_size}')\n",
    "print(f'Cityscapes (Test): {len(cityscapes_test_dataset)} images, divided into {len(cityscapes_test_dataloader)} batches of size {cityscapes_test_dataloader.batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from utils import poly_lr_scheduler, fast_hist, per_class_iou\n",
    "\n",
    "def train_adversarial(gen, dis, g_criterion, d_criterion, g_optimizer, d_optimizer, lambda_adv, s_dataloader, t_dataloader, class_names, device, n_epochs, model_name):    \n",
    "    n_classes = len(class_names)\n",
    "    best_miou = 0.0\n",
    "    best_class_iou = np.zeros(n_classes)\n",
    "    best_epoch = 0\n",
    "    all_train_miou = []\n",
    "    all_test_miou = []\n",
    "\n",
    "    #Initialize the labels for the adversarial training\n",
    "    source_label = 0\n",
    "    target_label = 1\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start = time.time()      \n",
    "\n",
    "        gen.train()\n",
    "        dis.train()\n",
    "\n",
    "        #train_hist = np.zeros((n_classes, n_classes))\n",
    "\n",
    "        #Train G\n",
    "        #Don't accumulate gradients in D\n",
    "        for param in dis.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        source_train_loop = tqdm(enumerate(s_dataloader), total=len(s_dataloader), leave=False)\n",
    "        #Train G with source data\n",
    "        for i, (inputs, labels) in source_train_loop:\n",
    "            if i == 10:\n",
    "                break\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            pred1, _, _ = gen(inputs)\n",
    "            seg_loss = g_criterion(pred1, labels)\n",
    "            seg_loss.backward()\n",
    "\n",
    "        target_train_loop = tqdm(enumerate(t_dataloader), total=len(t_dataloader), leave=False)\n",
    "        #Train G with target data\n",
    "        for i, (inputs, _) in target_train_loop:\n",
    "            if i == 3:\n",
    "                break\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            pred_target1, _, _ = gen(inputs)\n",
    "            d_out1 = dis(F.softmax(pred_target1, dim=1))#F.softmax(pred_target1, dim=1))\n",
    "            adv_loss = d_criterion(d_out1, source_label)\n",
    "            d_loss = lambda_adv * adv_loss\n",
    "            d_loss.backward()\n",
    "\n",
    "            #Train D\n",
    "\n",
    "            #Bring back gradients in D\n",
    "            for param in dis.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            #Train D with source data\n",
    "            d_out1 = dis(pred1.detach())#F.softmax(pred1, dim=1)\n",
    "            d_loss = d_criterion(d_out1, source_label)\n",
    "            d_loss.backward()\n",
    "\n",
    "            #Train D with target data\n",
    "            d_out1 = dis(pred_target1.detach())#F.softmax(pred_target1, dim=1)\n",
    "            d_loss = d_criterion(d_out1, target_label)\n",
    "            d_loss.backward()\n",
    "\n",
    "\n",
    "            \n",
    "            g_optimizer.step()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            #train_hist += fast_hist(labels.cpu().numpy(), predictions.cpu().numpy(), n_classes)\n",
    "            #train_loop.set_description(f'Epoch {epoch+1}/{n_epochs} (Train)')\n",
    "            \n",
    "        #train_class_iou = 100*per_class_iou(train_hist)\n",
    "        #train_miou = np.mean(train_class_iou)\n",
    "        #all_train_miou.append(train_miou)\n",
    "        \n",
    "        gen.eval()\n",
    "        test_hist = np.zeros((n_classes, n_classes))\n",
    "        test_loop = tqdm(enumerate(t_dataloader), total=len(t_dataloader), leave=False)\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs, labels) in test_loop:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = gen(inputs)\n",
    "                \n",
    "                predictions = torch.argmax(outputs, dim=1)\n",
    "                test_hist += fast_hist(labels.cpu().numpy(), predictions.cpu().numpy(), n_classes)\n",
    "                test_loop.set_description(f'Epoch {epoch+1}/{n_epochs} (Test)')\n",
    "                            \n",
    "        test_class_iou = 100*per_class_iou(test_hist)\n",
    "        test_miou = np.mean(test_class_iou)\n",
    "        all_test_miou.append(test_miou)\n",
    "        \n",
    "        #Create a checkpoint dictionary\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': gen.state_dict(),\n",
    "            'optimizer_state_dict': g_optimizer.state_dict(),\n",
    "            #'train_class_iou': train_class_iou,\n",
    "            #'train_miou': train_miou,\n",
    "            'test_class_iou': test_class_iou,\n",
    "            'test_miou': test_miou,\n",
    "        }\n",
    "\n",
    "        #torch.save(checkpoint, f'checkpoints/{model_name}_checkpoint_epoch_{epoch+1}.pth')\n",
    "        \n",
    "        #Early stopping condition\n",
    "        if test_miou > best_miou:\n",
    "            best_miou = test_miou\n",
    "            best_class_iou = test_class_iou\n",
    "            best_epoch = epoch\n",
    "            #torch.save(checkpoint, f'checkpoints/{model_name}_best_epoch_{epoch+1}.pth')\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        #print(f'\\nEpoch {epoch+1}/{n_epochs} [{(end-start) // 60:.0f}m {(end-start) % 60:.0f}s]: Train mIoU={train_miou:.2f}%, Test mIoU={test_miou:.2f}%')\n",
    "        print(f'\\nEpoch {epoch+1}/{n_epochs} [{(end-start) // 60:.0f}m {(end-start) % 60:.0f}s]: Test mIoU={test_miou:.2f}%')\n",
    "        for class_name, iou in zip(class_names, test_class_iou):\n",
    "            print(f'{class_name}: {iou:.2f}%', end=' ')\n",
    "\n",
    "    print(f'\\nBest mIoU={best_miou:.2f}% at epoch {best_epoch+1}')\n",
    "    for class_name, iou in zip(class_names, best_class_iou):\n",
    "        print(f'{class_name}: {iou:.2f}%', end=' ')\n",
    "\n",
    "    return all_train_miou, all_test_miou, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the segmentation network (our Generator) with the pretrained weights\n",
    "generator_model = BiSeNet(num_classes=19, context_path='resnet18').to(device)\n",
    "\n",
    "#Set up the loss function and the optimizer for the Generator\n",
    "g_criterion = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
    "g_optimizer = torch.optim.SGD(generator_model.parameters(), lr=2.5e-2, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up the Discriminators\n",
    "discriminator_model = FCDiscriminator(num_classes=19).to(device)\n",
    "\n",
    "#Set up the loss functions and the optimizers for the Discriminators\n",
    "d_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "d_optimizer = torch.optim.Adam(discriminator_model.parameters(), lr=1e-4, betas=(0.9, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_miou, all_test_miou, best_epoch = train_adversarial(generator_model, discriminator_model,\n",
    "                                                              g_criterion, d_criterion, g_optimizer, d_optimizer, lambda_adv,\n",
    "                                                              gta5_train_dataloader_aug1, cityscapes_test_dataloader,\n",
    "                                                              class_names, device, n_epochs, model_name='Adversarial')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
